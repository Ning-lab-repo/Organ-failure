{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "all_features = pd.read_csv('all_features.csv')\n",
    "y = all_features['heart']\n",
    "X = all_features.drop(columns=['heart'])\n",
    "\n",
    "# Custom scoring functions\n",
    "def sensitivity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return cm[1, 1] / (cm[1, 1] + cm[1, 0])\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "\n",
    "\n",
    "# Cross-validation configuration\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(penalty='l1', max_iter=10000, C=1, solver='saga'),\n",
    "    'SVM': SVC(kernel='rbf', C=1, probability=True),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=2500, max_depth=None, min_samples_split=2, min_samples_leaf=1, n_jobs=10),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(10, 50), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001),\n",
    "    'GBDT': GradientBoostingClassifier(learning_rate=0.1, max_depth=10, n_estimators=200),\n",
    "    'AdaBoost': AdaBoostClassifier(learning_rate=0.2, n_estimators=200, random_state=42),\n",
    "    'XGBoost': XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=200, use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'LightGBM': LGBMClassifier(learning_rate=0.1, max_depth=10, n_estimators=200, random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(depth=10, iterations=200, learning_rate=0.1, verbose=0, random_state=42)\n",
    "}\n",
    "\n",
    "# Store cross-validation results\n",
    "results = []\n",
    "roc_curves = {}\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for name, model in models.items():\n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    sensitivity_scores = []\n",
    "    specificity_scores = []\n",
    "    ppv_scores = []\n",
    "    npv_scores = []\n",
    "    f1_scores = []\n",
    "    mcc_scores = []\n",
    "    \n",
    "    y_true_all = []\n",
    "    y_pred_proba_all = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = model.predict(X_test_fold)\n",
    "        y_pred_proba_fold = model.predict_proba(X_test_fold)[:, 1]\n",
    "        \n",
    "        y_true_all.extend(y_test_fold)\n",
    "        y_pred_proba_all.extend(y_pred_proba_fold)\n",
    "        \n",
    "        auc_scores.append(roc_auc_score(y_test_fold, y_pred_proba_fold))\n",
    "        accuracy_scores.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "        sensitivity_scores.append(sensitivity_score(y_test_fold, y_pred_fold))\n",
    "        specificity_scores.append(specificity_score(y_test_fold, y_pred_fold))\n",
    "        ppv_scores.append(precision_score(y_test_fold, y_pred_fold))\n",
    "        npv_scores.append(precision_score(y_test_fold, y_pred_fold, pos_label=0))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        mcc_scores.append(matthews_corrcoef(y_test_fold, y_pred_fold))\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Fold': len(auc_scores),\n",
    "            'AUC': auc_scores[-1],\n",
    "            'Accuracy': accuracy_scores[-1],\n",
    "            'Sensitivity': sensitivity_scores[-1],\n",
    "            'Specificity': specificity_scores[-1],\n",
    "            'PPV': ppv_scores[-1],\n",
    "            'NPV': npv_scores[-1],\n",
    "            'F1 Score': f1_scores[-1],\n",
    "            'MCC': mcc_scores[-1]\n",
    "        })\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true_all, y_pred_proba_all)\n",
    "    roc_curves[name] = (fpr, tpr, roc_auc_score(y_true_all, y_pred_proba_all))\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Mean AUC: {np.mean(auc_scores):.4f} (+/- {np.std(auc_scores):.4f})\")\n",
    "    print(f\"  Mean Accuracy: {np.mean(accuracy_scores):.4f} (+/- {np.std(accuracy_scores):.4f})\")\n",
    "    print(f\"  Mean Sensitivity: {np.mean(sensitivity_scores):.4f} (+/- {np.std(sensitivity_scores):.4f})\")\n",
    "    print(f\"  Mean Specificity: {np.mean(specificity_scores):.4f} (+/- {np.std(specificity_scores):.4f})\")\n",
    "    print(f\"  Mean PPV: {np.mean(ppv_scores):.4f} (+/- {np.std(ppv_scores):.4f})\")\n",
    "    print(f\"  Mean NPV: {np.mean(npv_scores):.4f} (+/- {np.std(npv_scores):.4f})\")\n",
    "    print(f\"  Mean F1 Score: {np.mean(f1_scores):.4f} (+/- {np.std(f1_scores):.4f})\")\n",
    "    print(f\"  Mean MCC: {np.mean(mcc_scores):.4f} (+/- {np.std(mcc_scores):.4f})\")\n",
    "    print()\n",
    "\n",
    "# Compute confidence intervals\n",
    "bootstrap_iterations = 1000\n",
    "confidence_level = 95\n",
    "bootstrap_results = {name: [] for name in models.keys()}\n",
    "conf_intervals = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_true_all = []\n",
    "    y_pred_proba_all = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_proba_fold = model.predict_proba(X_test_fold)[:, 1]\n",
    "        \n",
    "        y_true_all.extend(y_test_fold)\n",
    "        y_pred_proba_all.extend(y_pred_proba_fold)\n",
    "    \n",
    "    y_true_all = np.array(y_true_all)\n",
    "    y_pred_proba_all = np.array(y_pred_proba_all)\n",
    "    \n",
    "    for _ in range(bootstrap_iterations):\n",
    "        y_true_bootstrap, y_pred_proba_bootstrap = resample(y_true_all, y_pred_proba_all)\n",
    "        bootstrap_results[name].append(roc_auc_score(y_true_bootstrap, y_pred_proba_bootstrap))\n",
    "    \n",
    "    lower_bound = np.percentile(bootstrap_results[name], (100 - confidence_level) / 2)\n",
    "    upper_bound = np.percentile(bootstrap_results[name], 100 - (100 - confidence_level) / 2)\n",
    "    \n",
    "    conf_intervals[name] = (lower_bound, upper_bound)\n",
    "    \n",
    "    print(f\"{name} AUC 95% CI: {lower_bound:.4f} - {upper_bound:.4f}\")\n",
    "\n",
    "# Convert results to DataFrame and save as CSV file\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv('cv_failure.csv', index=False)\n",
    "\n",
    "print(\"Cross-validation results saved to 'cv_results.csv'\")\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, (fpr, tpr, auc) in roc_curves.items():\n",
    "    lower_bound, upper_bound = conf_intervals[name]\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.2f}, 95% CI: {lower_bound:.2f} - {upper_bound:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
